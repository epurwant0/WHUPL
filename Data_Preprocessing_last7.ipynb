{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abc97c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67904155",
   "metadata": {},
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('Resources/Car_Data.xlsx')\n",
    "#df1 = pd.read_excel(xls, 'Volkswagon')\n",
    "#df2 = pd.read_excel(xls, 'Toyota')\n",
    "#df3 = pd.read_excel(xls, 'Porsche')\n",
    "#df4 = pd.read_excel(xls, 'Mercedes')\n",
    "#df5 = pd.read_excel(xls, 'Maserati')\n",
    "#df6 = pd.read_excel(xls, 'Lincoln')\n",
    "#df7 = pd.read_excel(xls, 'Lexus')\n",
    "df8 = pd.read_excel(xls, 'Kia')\n",
    "df9 = pd.read_excel(xls, 'Landrover')\n",
    "#df10 = pd.read_excel(xls, 'Volkswagon')\n",
    "df11 = pd.read_excel(xls, 'Honda')\n",
    "df12 = pd.read_excel(xls, 'Hyundai')\n",
    "df13 = pd.read_excel(xls, 'Acura')\n",
    "df14 = pd.read_excel(xls, 'Audi')\n",
    "df15 = pd.read_excel(xls, 'BMW')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6f00feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    new_df = df.dropna(how='any')\n",
    "    new_df['formatted_sold_date'] = pd.to_datetime(new_df['sold_date'], format='%Y-%m-%d-%H.%M.%S.%f')\n",
    "    cc_df = new_df.drop(columns=['sold_date'])\n",
    "    cc_df['condition_grade'] = cc_df['condition_grade'].replace(\n",
    "    {'SL': 0, 'RG': 20, 'PR': 10, 'EC':50, 'CL':40, 'AV':30})\n",
    "\n",
    "    return cc_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6c34e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-ecff727c1718>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['formatted_sold_date'] = pd.to_datetime(new_df['sold_date'], format='%Y-%m-%d-%H.%M.%S.%f')\n",
      "<ipython-input-26-ecff727c1718>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['formatted_sold_date'] = pd.to_datetime(new_df['sold_date'], format='%Y-%m-%d-%H.%M.%S.%f')\n",
      "<ipython-input-26-ecff727c1718>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['formatted_sold_date'] = pd.to_datetime(new_df['sold_date'], format='%Y-%m-%d-%H.%M.%S.%f')\n",
      "<ipython-input-26-ecff727c1718>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['formatted_sold_date'] = pd.to_datetime(new_df['sold_date'], format='%Y-%m-%d-%H.%M.%S.%f')\n",
      "<ipython-input-26-ecff727c1718>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['formatted_sold_date'] = pd.to_datetime(new_df['sold_date'], format='%Y-%m-%d-%H.%M.%S.%f')\n",
      "<ipython-input-26-ecff727c1718>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['formatted_sold_date'] = pd.to_datetime(new_df['sold_date'], format='%Y-%m-%d-%H.%M.%S.%f')\n",
      "<ipython-input-26-ecff727c1718>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['formatted_sold_date'] = pd.to_datetime(new_df['sold_date'], format='%Y-%m-%d-%H.%M.%S.%f')\n"
     ]
    }
   ],
   "source": [
    "clean_df8 = clean_data(df8)\n",
    "clean_df9 = clean_data(df9)\n",
    "clean_df11 = clean_data(df11)\n",
    "clean_df12 = clean_data(df12)\n",
    "clean_df13 = clean_data(df13)\n",
    "clean_df14 = clean_data(df14)\n",
    "clean_df15 = clean_data(df15)\n",
    "# for df in df_list:\n",
    "#     clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8a1cc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auction_code</th>\n",
       "      <th>car_year</th>\n",
       "      <th>color</th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>subseries</th>\n",
       "      <th>body</th>\n",
       "      <th>engine</th>\n",
       "      <th>transmission</th>\n",
       "      <th>mileage</th>\n",
       "      <th>condition_grade</th>\n",
       "      <th>times_run</th>\n",
       "      <th>sold_date</th>\n",
       "      <th>seller</th>\n",
       "      <th>sale_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVAA</td>\n",
       "      <td>2018</td>\n",
       "      <td>BLUE</td>\n",
       "      <td>KIA</td>\n",
       "      <td>FORTE</td>\n",
       "      <td>S</td>\n",
       "      <td>4DSN</td>\n",
       "      <td>4G</td>\n",
       "      <td>A</td>\n",
       "      <td>2919</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-06-28-00.00.00.000000</td>\n",
       "      <td>4918692</td>\n",
       "      <td>13800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NVAA</td>\n",
       "      <td>2017</td>\n",
       "      <td>PURPLE</td>\n",
       "      <td>KIA</td>\n",
       "      <td>OPTIMA</td>\n",
       "      <td>LX</td>\n",
       "      <td>4DSN</td>\n",
       "      <td>4G</td>\n",
       "      <td>A</td>\n",
       "      <td>20406</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-06-28-00.00.00.000000</td>\n",
       "      <td>4918691</td>\n",
       "      <td>13700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVAA</td>\n",
       "      <td>2015</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>KIA</td>\n",
       "      <td>K900</td>\n",
       "      <td>PREMIUM</td>\n",
       "      <td>4DSN</td>\n",
       "      <td>8G</td>\n",
       "      <td>A</td>\n",
       "      <td>32080</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-06-28-00.00.00.000000</td>\n",
       "      <td>4918692</td>\n",
       "      <td>19400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NVAA</td>\n",
       "      <td>2015</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>KIA</td>\n",
       "      <td>OPTIMA</td>\n",
       "      <td>LX</td>\n",
       "      <td>4DSN</td>\n",
       "      <td>4G</td>\n",
       "      <td>A</td>\n",
       "      <td>29990</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-06-28-00.00.00.000000</td>\n",
       "      <td>4918691</td>\n",
       "      <td>11200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NVAA</td>\n",
       "      <td>2017</td>\n",
       "      <td>GRAY</td>\n",
       "      <td>KIA</td>\n",
       "      <td>SORENTO AWD 4C</td>\n",
       "      <td>LX</td>\n",
       "      <td>SUV</td>\n",
       "      <td>4G</td>\n",
       "      <td>A</td>\n",
       "      <td>31797</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-06-28-00.00.00.000000</td>\n",
       "      <td>4918691</td>\n",
       "      <td>14700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  auction_code  car_year   color make           model subseries  body engine  \\\n",
       "0         NVAA      2018    BLUE  KIA           FORTE         S  4DSN     4G   \n",
       "1         NVAA      2017  PURPLE  KIA          OPTIMA        LX  4DSN     4G   \n",
       "2         NVAA      2015  SILVER  KIA            K900   PREMIUM  4DSN     8G   \n",
       "3         NVAA      2015   BLACK  KIA          OPTIMA        LX  4DSN     4G   \n",
       "4         NVAA      2017    GRAY  KIA  SORENTO AWD 4C        LX   SUV     4G   \n",
       "\n",
       "  transmission mileage condition_grade  times_run                   sold_date  \\\n",
       "0            A    2919              43          1  2019-06-28-00.00.00.000000   \n",
       "1            A   20406              41          1  2019-06-28-00.00.00.000000   \n",
       "2            A   32080              40          1  2019-06-28-00.00.00.000000   \n",
       "3            A   29990              38          1  2019-06-28-00.00.00.000000   \n",
       "4            A   31797              36          2  2019-06-28-00.00.00.000000   \n",
       "\n",
       "    seller  sale_price  \n",
       "0  4918692       13800  \n",
       "1  4918691       13700  \n",
       "2  4918692       19400  \n",
       "3  4918691       11200  \n",
       "4  4918691       14700  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = df8.dropna(how='any')\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "663d8d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 71262 entries, 0 to 82980\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   auction_code     71262 non-null  object\n",
      " 1   car_year         71262 non-null  int64 \n",
      " 2   color            71262 non-null  object\n",
      " 3   make             71262 non-null  object\n",
      " 4   model            71262 non-null  object\n",
      " 5   subseries        71262 non-null  object\n",
      " 6   body             71262 non-null  object\n",
      " 7   engine           71262 non-null  object\n",
      " 8   transmission     71262 non-null  object\n",
      " 9   mileage          71262 non-null  object\n",
      " 10  condition_grade  71262 non-null  object\n",
      " 11  times_run        71262 non-null  int64 \n",
      " 12  sold_date        71262 non-null  object\n",
      " 13  seller           71262 non-null  object\n",
      " 14  sale_price       71262 non-null  int64 \n",
      "dtypes: int64(3), object(12)\n",
      "memory usage: 8.7+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff300ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries: 0\n",
      "Duplicate entries: 1\n",
      "Duplicate entries: 2\n",
      "Duplicate entries: 1\n",
      "Duplicate entries: 0\n",
      "Duplicate entries: 1\n",
      "Duplicate entries: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Duplicate entries: {clean_df8.duplicated().sum()}\")\n",
    "print(f\"Duplicate entries: {clean_df9.duplicated().sum()}\")\n",
    "print(f\"Duplicate entries: {clean_df11.duplicated().sum()}\")\n",
    "print(f\"Duplicate entries: {clean_df12.duplicated().sum()}\")\n",
    "print(f\"Duplicate entries: {clean_df13.duplicated().sum()}\")\n",
    "print(f\"Duplicate entries: {clean_df14.duplicated().sum()}\")\n",
    "print(f\"Duplicate entries: {clean_df15.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6123fb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries: 0\n"
     ]
    }
   ],
   "source": [
    "no_dups_df9 = clean_df9.drop_duplicates()\n",
    "print(f\"Duplicate entries: {no_dups_df9.duplicated().sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50940ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries: 0\n"
     ]
    }
   ],
   "source": [
    "no_dups_df11 = clean_df9.drop_duplicates()\n",
    "print(f\"Duplicate entries: {no_dups_df11.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6141293d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries: 0\n"
     ]
    }
   ],
   "source": [
    "no_dups_df12 = clean_df9.drop_duplicates()\n",
    "print(f\"Duplicate entries: {no_dups_df12.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06c1fff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate entries: 0\n"
     ]
    }
   ],
   "source": [
    "no_dups_df14 = clean_df9.drop_duplicates()\n",
    "print(f\"Duplicate entries: {no_dups_df14.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed8dc504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out csv's to output folder\n",
    "clean_df8.to_csv('Output/KIA.csv')\n",
    "clean_df9.to_csv('Output/Land_Rover.csv')\n",
    "clean_df11.to_csv('Output/Honda.csv')\n",
    "clean_df12.to_csv('Output/Hyundai.csv')\n",
    "clean_df13.to_csv('Output/Acura.csv')\n",
    "clean_df14.to_csv('Output/Audi.csv')\n",
    "clean_df15.to_csv('Output/BMW.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33d6f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8_dummies = pd.get_dummies(clean_df8)\n",
    "df9_dummies = pd.get_dummies(clean_df9)\n",
    "df11_dummies = pd.get_dummies(clean_df11)\n",
    "df12_dummies = pd.get_dummies(clean_df12)\n",
    "df13_dummies = pd.get_dummies(clean_df13)\n",
    "df14_dummies = pd.get_dummies(clean_df14)\n",
    "df15_dummies = pd.get_dummies(clean_df15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bea4b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the label to create the X data\n",
    "X_8 = df8_dummies.drop('sale_price', axis=1)\n",
    "X_9 = df9_dummies.drop('sale_price', axis=1)\n",
    "X_11 = df11_dummies.drop('sale_price', axis=1)\n",
    "X_12 = df12_dummies.drop('sale_price', axis=1)\n",
    "X_13 = df13_dummies.drop('sale_price', axis=1)\n",
    "X_14 = df14_dummies.drop('sale_price', axis=1)\n",
    "X_15 = df15_dummies.drop('sale_price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8d4b47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_8 = df8_dummies[\"sale_price\"]\n",
    "y_9 = df9_dummies[\"sale_price\"]\n",
    "y_11 = df11_dummies[\"sale_price\"]\n",
    "y_12 = df12_dummies[\"sale_price\"]\n",
    "y_13 = df13_dummies[\"sale_price\"]\n",
    "y_14 = df14_dummies[\"sale_price\"]\n",
    "y_15 = df15_dummies[\"sale_price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72d51bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train8, X_test8, y_train8, y_test8 = train_test_split(X_8, y_8, random_state=1)\n",
    "X_train9, X_test9, y_train9, y_test9 = train_test_split(X_9, y_9, random_state=1)\n",
    "X_train11, X_test11, y_train11, y_test11 = train_test_split(X_11, y_11, random_state=1)\n",
    "X_train12, X_test12, y_train12, y_test12 = train_test_split(X_12, y_12, random_state=1)\n",
    "X_train5, X_test13, y_train13, y_test13 = train_test_split(X_13, y_13, random_state=1)\n",
    "X_train6, X_test14, y_train14, y_test14 = train_test_split(X_14, y_14, random_state=1)\n",
    "X_train7, X_test15, y_train15, y_test15 = train_test_split(X_15, y_15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "291484c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The DTypes <class 'numpy.dtype[datetime64]'> and <class 'numpy.dtype[int64]'> do not have a common DType. For example they cannot be stored in a single array unless the dtype is `object`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-f402c05a620d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Scaling the X data by using StandardScaler()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mscaler1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX_train_scaled8\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_train_scaled8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    728\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    764\u001b[0m         \"\"\"\n\u001b[0;32m    765\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"n_samples_seen_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 766\u001b[1;33m         X = self._validate_data(X, accept_sparse=('csr', 'csc'),\n\u001b[0m\u001b[0;32m    767\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m                                 force_all_finite='allow-nan', reset=first_call)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'no_validation'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdtypes_orig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m             \u001b[0mdtype_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdtypes_orig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mresult_type\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: The DTypes <class 'numpy.dtype[datetime64]'> and <class 'numpy.dtype[int64]'> do not have a common DType. For example they cannot be stored in a single array unless the dtype is `object`."
     ]
    }
   ],
   "source": [
    "# Scaling the X data by using StandardScaler()\n",
    "scaler1 = StandardScaler().fit(X_train8)\n",
    "X_train_scaled8 = scaler.transform(X_train8)\n",
    "X_train_scaled8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e1587a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df_shopping[['Age', 'Annual Income', 'Spending Score (1-100)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b87959",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
